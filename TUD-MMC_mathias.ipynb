{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Results of \"TUD-MMC at MediaEval 2016: Context of Experience task\" by Wang & Liem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import xml.etree.ElementTree as ET\n",
    "train_path = \"res/coe_dataset_icpr/dev_set/\"\n",
    "test_path = \"res/coe_dataset_icpr/test_set/\"\n",
    "\n",
    "audio_folder = \"audio_descriptors/\"\n",
    "text_folder = \"text_descriptors/\"\n",
    "vis_folder = \"vis_descriptors/\"\n",
    "metadata_folder = \"XML/\"\n",
    "\n",
    "train_entries_path = \"res/CoeTraining.csv\"\n",
    "test_entries_path = \"res/CoeTrainingTest.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Features are built in the manner described in the paper of Wang & Liem or \"Right Inflight? A Dataset for Exploring the Automatic\n",
    "Prediction of Movies Suitable for a Watching Situation\" (https://mmsys2016.itec.aau.at/papers/MMSYS/a45-riegler.pdf), if Wang & Liem do not provide any information.\n",
    "\n",
    "This leads to following set-up:\n",
    "\n",
    "Metadata: (language, year published, genre, country, runtime and age rating) - from XML<br>\n",
    "Text: as is td-idf <br>\n",
    "Audio: Averaged of all Frames (NaN to 0) - Mel-Frequency Cepstral Coefficients<br>\n",
    "Visual: as is - Histogram of Oriented Gradients (HOG) gray, Color Moments, local binary patterns (LBP) and Gray Level Run Length Matrix\n",
    "\n",
    "NOTE: Training data - invalid entry (2_states, also in test set), (Moulin_Rouge!.mp4, should be Moulin_Rouge! --> fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_train = pd.read_csv(train_entries_path)\n",
    "df_base_train = df_base_train[df_base_train['file_name'] != '2_States'] # remove invalid entry\n",
    "df_base_train.reset_index(inplace=True, drop=True)\n",
    "df_base_train.sort_values(by='file_name', inplace=True)\n",
    "df_base_train.head(5)\n",
    "df_targets_train = df_base_train['goodforairplanes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractors\n",
    "As the dataset was built in a manner that would have been considered dirty already in 2002 a lot of feature extraction is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features(file_name, use_train=True):\n",
    "    \"\"\"\n",
    "        returns 1x14 dataframe, with averaged Mel-Frequency Cepstral Coefficients + file_name\n",
    "    \"\"\"\n",
    "    base_path = train_path if use_train else test_path\n",
    "    file_path = os.path.join(base_path, audio_folder, file_name + \".csv\")\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(file_name, \" does not exist!\")\n",
    "        return pd.DataFrame(columns=[str(x) for x in range(13)] + ['file_name'])\n",
    "    df_audio = pd.read_csv(file_path, header=None).T # transpose (columns are rows)\n",
    "    df_audio = df_audio.fillna(0) # nan values are treated as 0\n",
    "    df_audio = pd.DataFrame(df_audio.mean(axis=0)).T # average accross columns\n",
    "    df_audio['file_name'] = file_name\n",
    "    return df_audio\n",
    "\n",
    "def get_all_audio_features(df, use_train=True):\n",
    "    \"\"\"\n",
    "        returns nx14 dataframe, containing audio features for all movies\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file_name in df['file_name']:\n",
    "        dfs.append(get_audio_features(file_name, use_train))\n",
    "    \n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def get_all_text_features(df, use_train=True):\n",
    "    \"\"\"\n",
    "        returns nx3284 dataframe, containing tf-idf features for all movies\n",
    "        the dataset creators messed up - contains several terms multiple times\n",
    "        ordered alphabetically (?) - Live_Nude_Girls and Transformers__Age_of_Extinction where switched (detected perchance)\n",
    "    \"\"\"\n",
    "    base_path = train_path if use_train else test_path\n",
    "    file_path = os.path.join(base_path, text_folder, \"tdf_idf_dev.csv\") \n",
    "    df_txt = pd.read_csv(file_path)\n",
    "    # the creators of the dataset missed how csv-files work - so we transpose and drop empty rows to get the correct format\n",
    "    cols = df_txt.columns \n",
    "    df_txt = df_txt.T.dropna()\n",
    "    df_txt.columns = cols\n",
    "    df_txt.reset_index(inplace=True, drop=True)\n",
    "    df_txt['file_name'] = sorted(df['file_name']) # we assume the info to be order alphabetically, as we do not have more info\n",
    "    return df_txt\n",
    "\n",
    "def get_vis_features(file_name, use_train=True):\n",
    "    \"\"\"\n",
    "        returns 1x1653 dataframe, with unspecified visual features + file_name\n",
    "        we assume that every single value in the csv is one feature\n",
    "        this may be wrong, as there are two rows and no documentation (again)\n",
    "    \"\"\"\n",
    "    base_path = train_path if use_train else test_path\n",
    "    file_path = os.path.join(base_path, vis_folder, file_name + \".csv\")\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(file_name, \" does not exist!\")\n",
    "        return pd.DataFrame(columns=[str(x) for x in range(1652)] + ['file_name'])\n",
    "    df_vis = pd.read_csv(file_path, header=None)\n",
    "    df_vis = pd.DataFrame(pd.concat([df_vis.loc[0,:], df_vis.loc[1,:]])).reset_index(drop=True).T # treat each value as single feature (-> no aggregation)\n",
    "    df_vis['file_name'] = file_name\n",
    "    return df_vis\n",
    "\n",
    "def get_all_vis_features(df, use_train=True):\n",
    "    \"\"\"\n",
    "        returns nx1653 dataframe, containing visual features for all movies\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file_name in df['file_name']:\n",
    "        dfs.append(get_vis_features(file_name, use_train))\n",
    "    \n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def get_meta_features(file_name, use_train=True):\n",
    "    \"\"\"\n",
    "        returns 1x7 dataframe, with metadata features + file_name\n",
    "        One Hot Encoding is not applied here, this should happen later\n",
    "    \"\"\"\n",
    "    base_path = train_path if use_train else test_path\n",
    "    file_path = os.path.join(base_path, metadata_folder, file_name + \".xml\")\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(file_name, \" does not exist!\")\n",
    "        return pd.DataFrame(columns=['country', 'genre', 'language', 'rated', 'runtime', 'year', 'file_name'])\n",
    "    etree = ET.parse(file_path)\n",
    "    movie = etree.getroot().find('movie')\n",
    "    mv = {}\n",
    "    mv['language'] = [movie.get('language')]\n",
    "    mv['year'] = [int(movie.get('year'))]\n",
    "    mv['genre'] = [movie.get('genre')]\n",
    "    mv['country'] = [movie.get('country')]\n",
    "    mv['runtime'] = [int(movie.get('runtime')[:-4])]\n",
    "    mv['rated'] = [movie.get('rated')]\n",
    "\n",
    "    df_meta = pd.DataFrame.from_dict(mv)\n",
    "    df_meta['file_name'] = file_name\n",
    "    \n",
    "    return df_meta\n",
    "\n",
    "def get_all_meta_features(df, use_train=True):\n",
    "    \"\"\"\n",
    "        returns nx7 dataframe, containing metadata features for all movies\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file_name in df['file_name']:\n",
    "        dfs.append(get_meta_features(file_name, use_train))\n",
    "    \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.828814</td>\n",
       "      <td>-5.674521</td>\n",
       "      <td>1.670346</td>\n",
       "      <td>1.143263</td>\n",
       "      <td>-0.635255</td>\n",
       "      <td>1.269376</td>\n",
       "      <td>0.633811</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>0.164257</td>\n",
       "      <td>-1.494813</td>\n",
       "      <td>-0.292583</td>\n",
       "      <td>0.086875</td>\n",
       "      <td>-0.914582</td>\n",
       "      <td>A_Fish_Called_Wanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.908715</td>\n",
       "      <td>-6.380989</td>\n",
       "      <td>1.361790</td>\n",
       "      <td>-1.483354</td>\n",
       "      <td>-0.670040</td>\n",
       "      <td>-1.626537</td>\n",
       "      <td>0.466197</td>\n",
       "      <td>-1.888169</td>\n",
       "      <td>0.848654</td>\n",
       "      <td>-0.990286</td>\n",
       "      <td>0.673634</td>\n",
       "      <td>-0.972964</td>\n",
       "      <td>-0.141539</td>\n",
       "      <td>A_Goofy_Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.390978</td>\n",
       "      <td>-6.725758</td>\n",
       "      <td>0.579762</td>\n",
       "      <td>-0.271885</td>\n",
       "      <td>-0.175640</td>\n",
       "      <td>-0.845690</td>\n",
       "      <td>-0.699064</td>\n",
       "      <td>-0.578434</td>\n",
       "      <td>0.537249</td>\n",
       "      <td>-1.387373</td>\n",
       "      <td>0.747223</td>\n",
       "      <td>-0.887580</td>\n",
       "      <td>-0.205273</td>\n",
       "      <td>A_Million_Ways_to_Die_in_the_West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.743484</td>\n",
       "      <td>-3.722123</td>\n",
       "      <td>2.780418</td>\n",
       "      <td>0.756402</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>-0.960622</td>\n",
       "      <td>-0.435575</td>\n",
       "      <td>-0.176729</td>\n",
       "      <td>1.665236</td>\n",
       "      <td>-2.068548</td>\n",
       "      <td>1.211791</td>\n",
       "      <td>-0.358194</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>A_Single_Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.354709</td>\n",
       "      <td>-5.609515</td>\n",
       "      <td>-1.303409</td>\n",
       "      <td>-0.831993</td>\n",
       "      <td>-0.518848</td>\n",
       "      <td>-0.019373</td>\n",
       "      <td>-0.500203</td>\n",
       "      <td>-0.897985</td>\n",
       "      <td>0.148561</td>\n",
       "      <td>-0.666728</td>\n",
       "      <td>0.033135</td>\n",
       "      <td>0.383797</td>\n",
       "      <td>-0.209412</td>\n",
       "      <td>American_Gangster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  66.828814 -5.674521  1.670346  1.143263 -0.635255  1.269376  0.633811   \n",
       "0  43.908715 -6.380989  1.361790 -1.483354 -0.670040 -1.626537  0.466197   \n",
       "0   3.390978 -6.725758  0.579762 -0.271885 -0.175640 -0.845690 -0.699064   \n",
       "0  57.743484 -3.722123  2.780418  0.756402  0.043743 -0.960622 -0.435575   \n",
       "0  65.354709 -5.609515 -1.303409 -0.831993 -0.518848 -0.019373 -0.500203   \n",
       "\n",
       "          7         8         9        10        11        12  \\\n",
       "0  0.012407  0.164257 -1.494813 -0.292583  0.086875 -0.914582   \n",
       "0 -1.888169  0.848654 -0.990286  0.673634 -0.972964 -0.141539   \n",
       "0 -0.578434  0.537249 -1.387373  0.747223 -0.887580 -0.205273   \n",
       "0 -0.176729  1.665236 -2.068548  1.211791 -0.358194  0.738827   \n",
       "0 -0.897985  0.148561 -0.666728  0.033135  0.383797 -0.209412   \n",
       "\n",
       "                           file_name  \n",
       "0                A_Fish_Called_Wanda  \n",
       "0                      A_Goofy_Movie  \n",
       "0  A_Million_Ways_to_Die_in_the_West  \n",
       "0                       A_Single_Man  \n",
       "0                  American_Gangster  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio_train = get_all_audio_features(df_base_train)\n",
    "df_audio_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24000</th>\n",
       "      <th>baby</th>\n",
       "      <th>baseball</th>\n",
       "      <th>big</th>\n",
       "      <th>doc</th>\n",
       "      <th>escort</th>\n",
       "      <th>frozen</th>\n",
       "      <th>heroes</th>\n",
       "      <th>high</th>\n",
       "      <th>huck</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>yorks</th>\n",
       "      <th>young</th>\n",
       "      <th>young.1</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngja</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zellweger</th>\n",
       "      <th>zoologists</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A_Fish_Called_Wanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A_Goofy_Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A_Million_Ways_to_Die_in_the_West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A_Single_Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>American_Gangster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   24000  baby  baseball  big  doc  escort  frozen  heroes  high  huck  \\\n",
       "0    0.0   0.0       0.0  0.0  0.0     0.0     0.0     0.0   0.0   0.0   \n",
       "1    0.0   0.0       0.0  0.0  0.0     0.0     0.0     0.0   0.0   0.0   \n",
       "2    0.0   0.0       0.0  0.0  0.0     0.0     0.0     0.0   0.0   0.0   \n",
       "3    0.0   0.0       0.0  0.0  0.0     0.0     0.0     0.0   0.0   0.0   \n",
       "4    0.0   0.0       0.0  0.0  0.0     0.0     0.0     0.0   0.0   0.0   \n",
       "\n",
       "                 ...                      york  yorks  young  young.1  \\\n",
       "0                ...                  0.000000    0.0    0.0      0.0   \n",
       "1                ...                  0.000000    0.0    0.0      0.0   \n",
       "2                ...                  0.000000    0.0    0.0      0.0   \n",
       "3                ...                  0.000000    0.0    0.0      0.0   \n",
       "4                ...                  0.051657    0.0    0.0      0.0   \n",
       "\n",
       "   younger  youngja  zebra  zellweger  zoologists  \\\n",
       "0      0.0      0.0    0.0        0.0         0.0   \n",
       "1      0.0      0.0    0.0        0.0         0.0   \n",
       "2      0.0      0.0    0.0        0.0         0.0   \n",
       "3      0.0      0.0    0.0        0.0         0.0   \n",
       "4      0.0      0.0    0.0        0.0         0.0   \n",
       "\n",
       "                           file_name  \n",
       "0                A_Fish_Called_Wanda  \n",
       "1                      A_Goofy_Movie  \n",
       "2  A_Million_Ways_to_Die_in_the_West  \n",
       "3                       A_Single_Man  \n",
       "4                  American_Gangster  \n",
       "\n",
       "[5 rows x 3284 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txt_train = get_all_text_features(df_base_train)\n",
    "df_txt_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1643</th>\n",
       "      <th>1644</th>\n",
       "      <th>1645</th>\n",
       "      <th>1646</th>\n",
       "      <th>1647</th>\n",
       "      <th>1648</th>\n",
       "      <th>1649</th>\n",
       "      <th>1650</th>\n",
       "      <th>1651</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430310</td>\n",
       "      <td>0.38101</td>\n",
       "      <td>0.34082</td>\n",
       "      <td>0.31642</td>\n",
       "      <td>0.414650</td>\n",
       "      <td>0.385990</td>\n",
       "      <td>0.329380</td>\n",
       "      <td>0.31212</td>\n",
       "      <td>0.350670</td>\n",
       "      <td>0.342460</td>\n",
       "      <td>...</td>\n",
       "      <td>362.83</td>\n",
       "      <td>8.592300</td>\n",
       "      <td>9.142700</td>\n",
       "      <td>8.410100</td>\n",
       "      <td>8.792400</td>\n",
       "      <td>1483.3</td>\n",
       "      <td>417.21</td>\n",
       "      <td>892.59</td>\n",
       "      <td>435.28</td>\n",
       "      <td>A_Fish_Called_Wanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07302</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.11824</td>\n",
       "      <td>0.026991</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>...</td>\n",
       "      <td>20278.00</td>\n",
       "      <td>0.972010</td>\n",
       "      <td>1.365400</td>\n",
       "      <td>1.803200</td>\n",
       "      <td>1.463400</td>\n",
       "      <td>168740.0</td>\n",
       "      <td>20896.00</td>\n",
       "      <td>34434.00</td>\n",
       "      <td>20967.00</td>\n",
       "      <td>A_Goofy_Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>119950.00</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>729320.0</td>\n",
       "      <td>119950.00</td>\n",
       "      <td>230400.00</td>\n",
       "      <td>119950.00</td>\n",
       "      <td>A_Million_Ways_to_Die_in_the_West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9550.70</td>\n",
       "      <td>5.943300</td>\n",
       "      <td>6.021500</td>\n",
       "      <td>4.383900</td>\n",
       "      <td>5.428800</td>\n",
       "      <td>32242.0</td>\n",
       "      <td>10313.00</td>\n",
       "      <td>22308.00</td>\n",
       "      <td>9850.00</td>\n",
       "      <td>A_Single_Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231640</td>\n",
       "      <td>0.28629</td>\n",
       "      <td>0.30068</td>\n",
       "      <td>0.28118</td>\n",
       "      <td>0.244890</td>\n",
       "      <td>0.278490</td>\n",
       "      <td>0.290760</td>\n",
       "      <td>0.29380</td>\n",
       "      <td>0.161040</td>\n",
       "      <td>0.166850</td>\n",
       "      <td>...</td>\n",
       "      <td>109.62</td>\n",
       "      <td>17.237000</td>\n",
       "      <td>15.543000</td>\n",
       "      <td>13.671000</td>\n",
       "      <td>15.231000</td>\n",
       "      <td>53559.0</td>\n",
       "      <td>8637.40</td>\n",
       "      <td>18597.00</td>\n",
       "      <td>8679.00</td>\n",
       "      <td>American_Gangster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2        3         4         5         6        7  \\\n",
       "0  0.430310  0.38101  0.34082  0.31642  0.414650  0.385990  0.329380  0.31212   \n",
       "0  0.002031  0.00000  0.00000  0.07302  0.027533  0.005346  0.006015  0.11824   \n",
       "0  0.000000  0.00000  0.00000  0.00000  0.000000  0.000000  0.000000  0.00000   \n",
       "0  0.000000  0.00000  0.00000  0.00000  0.000000  0.000000  0.000000  0.00000   \n",
       "0  0.231640  0.28629  0.30068  0.28118  0.244890  0.278490  0.290760  0.29380   \n",
       "\n",
       "          8         9                ...                       1643  \\\n",
       "0  0.350670  0.342460                ...                     362.83   \n",
       "0  0.026991  0.005171                ...                   20278.00   \n",
       "0  0.000000  0.000000                ...                  119950.00   \n",
       "0  0.000000  0.000000                ...                    9550.70   \n",
       "0  0.161040  0.166850                ...                     109.62   \n",
       "\n",
       "        1644       1645       1646       1647      1648       1649       1650  \\\n",
       "0   8.592300   9.142700   8.410100   8.792400    1483.3     417.21     892.59   \n",
       "0   0.972010   1.365400   1.803200   1.463400  168740.0   20896.00   34434.00   \n",
       "0   0.000001   0.002466   0.000004   0.002466  729320.0  119950.00  230400.00   \n",
       "0   5.943300   6.021500   4.383900   5.428800   32242.0   10313.00   22308.00   \n",
       "0  17.237000  15.543000  13.671000  15.231000   53559.0    8637.40   18597.00   \n",
       "\n",
       "        1651                          file_name  \n",
       "0     435.28                A_Fish_Called_Wanda  \n",
       "0   20967.00                      A_Goofy_Movie  \n",
       "0  119950.00  A_Million_Ways_to_Die_in_the_West  \n",
       "0    9850.00                       A_Single_Man  \n",
       "0    8679.00                  American_Gangster  \n",
       "\n",
       "[5 rows x 1653 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vis_train = get_all_vis_features(df_base_train)\n",
    "df_vis_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>country</th>\n",
       "      <th>runtime</th>\n",
       "      <th>rated</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English, Italian, Russian</td>\n",
       "      <td>1988</td>\n",
       "      <td>Comedy, Crime</td>\n",
       "      <td>USA, UK</td>\n",
       "      <td>108</td>\n",
       "      <td>R</td>\n",
       "      <td>A_Fish_Called_Wanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>1995</td>\n",
       "      <td>Animation, Adventure, Comedy</td>\n",
       "      <td>USA</td>\n",
       "      <td>78</td>\n",
       "      <td>G</td>\n",
       "      <td>A_Goofy_Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English, Navajo, Mandarin</td>\n",
       "      <td>2014</td>\n",
       "      <td>Comedy, Western</td>\n",
       "      <td>USA</td>\n",
       "      <td>116</td>\n",
       "      <td>R</td>\n",
       "      <td>A_Million_Ways_to_Die_in_the_West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>2009</td>\n",
       "      <td>Drama</td>\n",
       "      <td>USA</td>\n",
       "      <td>99</td>\n",
       "      <td>R</td>\n",
       "      <td>A_Single_Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>2007</td>\n",
       "      <td>Biography, Crime, Drama</td>\n",
       "      <td>USA, UK</td>\n",
       "      <td>157</td>\n",
       "      <td>R</td>\n",
       "      <td>American_Gangster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    language  year                         genre  country  \\\n",
       "0  English, Italian, Russian  1988                 Comedy, Crime  USA, UK   \n",
       "0                    English  1995  Animation, Adventure, Comedy      USA   \n",
       "0  English, Navajo, Mandarin  2014               Comedy, Western      USA   \n",
       "0           English, Spanish  2009                         Drama      USA   \n",
       "0                    English  2007       Biography, Crime, Drama  USA, UK   \n",
       "\n",
       "   runtime rated                          file_name  \n",
       "0      108     R                A_Fish_Called_Wanda  \n",
       "0       78     G                      A_Goofy_Movie  \n",
       "0      116     R  A_Million_Ways_to_Die_in_the_West  \n",
       "0       99     R                       A_Single_Man  \n",
       "0      157     R                  American_Gangster  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_train = get_all_meta_features(df_base_train)\n",
    "df_meta_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # put NOTE into paper - not sure if correct bayes\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "class BaseClassifier:\n",
    "    \n",
    "    def __init__(self, clf, df_features, df_targets, clf_name, modality):\n",
    "        self.clf = clf\n",
    "        self.df_features = df_features\n",
    "        self.df_targets = df_targets\n",
    "        self.clf_name = clf_name\n",
    "        self.modality = modality\n",
    "        self.scoring = {'f1': 'f1_micro',\n",
    "                        'precision': 'precision_micro',\n",
    "                        'recall': 'recall_micro'}\n",
    "        \n",
    "    def cv(self, cv= 10, verbose=True):\n",
    "        np.random.seed(32143421)\n",
    "        if verbose:\n",
    "            print(f\"Starting cross validation for classifier {self.clf_name} and modality {self.modality}\")\n",
    "        \n",
    "        # TODO: this will return different results (CIs, Mean, variance,...)\n",
    "        return cross_validate(self.clf, self.get_lvw_feature_df(), self.df_targets, cv=cv, scoring=self.scoring, return_train_score=False)\n",
    "    \n",
    "    def get_lvw_feature_df(self):\n",
    "        # returns feature subset using Las Vegas Wrapper (TODO: logic + method to retrieve used features)\n",
    "        df_sub = self.df_features.drop('file_name', axis=1) # never use file name\n",
    "        return df_sub\n",
    "\n",
    "    \n",
    "class ClassifierFactory:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_metadata_classifiers(df_features, df_targets):\n",
    "        return [BaseClassifier(KNeighborsClassifier(), df_features, df_targets, 'k-Nearest neighbors', 'Metadata'),\n",
    "                BaseClassifier(NearestCentroid(), df_features, df_targets, 'Nearest mean classifier', 'Metadata'),\n",
    "                BaseClassifier(DecisionTreeClassifier(), df_features, df_targets, 'Decision tree', 'Metadata'),\n",
    "                BaseClassifier(LogisticRegression(), df_features, df_targets, 'Logistic regression', 'Metadata'),\n",
    "                BaseClassifier(SVC(gamma='auto'), df_features, df_targets, 'SVM (Gaussian Kernel)', 'Metadata'),\n",
    "                BaseClassifier(BaggingClassifier(), df_features, df_targets, 'Bagging', 'Metadata'),\n",
    "                BaseClassifier(RandomForestClassifier(n_estimators=10), df_features, df_targets, 'Random Forest', 'Metadata'),\n",
    "                BaseClassifier(AdaBoostClassifier(), df_features, df_targets, 'AdaBoost', 'Metadata'),\n",
    "                BaseClassifier(GradientBoostingClassifier(), df_features, df_targets, 'Gradient Boosting Tree', 'Metadata')]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_text_classifiers(df_features, df_targets):\n",
    "        return [BaseClassifier(GaussianNB(), df_features, df_targets, 'Naive Bayes', 'Textual'),\n",
    "                BaseClassifier(KNeighborsClassifier(), df_features, df_targets, 'k-Nearest neighbors', 'Textual'),\n",
    "                BaseClassifier(SVC(gamma='auto'), df_features, df_targets, 'SVM (Gaussian Kernel)', 'Textual')]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_visual_classifiers(df_features, df_targets):\n",
    "        return [BaseClassifier(KNeighborsClassifier(), df_features, df_targets, 'k-Nearest neighbors', 'Visual'),\n",
    "                BaseClassifier(DecisionTreeClassifier(), df_features, df_targets, 'Decision tree', 'Visual'),\n",
    "                BaseClassifier(LogisticRegression(), df_features, df_targets, 'Logistic regression', 'Visual'),\n",
    "                BaseClassifier(SVC(gamma='auto'), df_features, df_targets, 'SVM (Gaussian Kernel)', 'Visual'),\n",
    "                BaseClassifier(RandomForestClassifier(n_estimators=10), df_features, df_targets, 'Random Forest', 'Visual'),\n",
    "                BaseClassifier(AdaBoostClassifier(), df_features, df_targets, 'AdaBoost', 'Visual'),\n",
    "                BaseClassifier(GradientBoostingClassifier(), df_features, df_targets, 'Gradient Boosting Tree', 'Visual')]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_audio_classifiers(df_features, df_targets):\n",
    "        return [BaseClassifier(LogisticRegression(), df_features, df_targets, 'Logistic regression', 'Audio'),\n",
    "                BaseClassifier(GradientBoostingClassifier(), df_features, df_targets, 'Gradient Boosting Tree', 'Audio')]                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross validation for classifier Naive Bayes and modality Textual\n",
      "{'fit_time': array([0.05270934, 0.00700045, 0.00799942, 0.00900102, 0.00900102,\n",
      "       0.00699902, 0.00799966, 0.0079987 , 0.00699949, 0.00800085]), 'score_time': array([0.02099776, 0.00400043, 0.00299883, 0.00399876, 0.00400043,\n",
      "       0.00400043, 0.006001  , 0.00400162, 0.00300002, 0.00399852]), 'test_f1': array([0.27272727, 0.45454545, 0.3       , 0.66666667, 0.44444444,\n",
      "       0.44444444, 0.66666667, 0.55555556, 0.22222222, 0.66666667]), 'test_precision': array([0.27272727, 0.45454545, 0.3       , 0.66666667, 0.44444444,\n",
      "       0.44444444, 0.66666667, 0.55555556, 0.22222222, 0.66666667]), 'test_recall': array([0.27272727, 0.45454545, 0.3       , 0.66666667, 0.44444444,\n",
      "       0.44444444, 0.66666667, 0.55555556, 0.22222222, 0.66666667])}\n",
      "Starting cross validation for classifier k-Nearest neighbors and modality Textual\n",
      "{'fit_time': array([0.00700235, 0.00499797, 0.00500011, 0.00400043, 0.00500202,\n",
      "       0.00599861, 0.00499892, 0.00799942, 0.006001  , 0.00599742]), 'score_time': array([0.01799798, 0.01700139, 0.01599813, 0.01499844, 0.01700044,\n",
      "       0.01700044, 0.01699996, 0.01700163, 0.01599979, 0.0150001 ]), 'test_f1': array([0.54545455, 0.54545455, 0.5       , 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556]), 'test_precision': array([0.54545455, 0.54545455, 0.5       , 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556]), 'test_recall': array([0.54545455, 0.54545455, 0.5       , 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556])}\n",
      "Starting cross validation for classifier SVM (Gaussian Kernel) and modality Textual\n",
      "{'fit_time': array([0.02797151, 0.02699804, 0.02602839, 0.0270288 , 0.02900171,\n",
      "       0.02999997, 0.02802563, 0.02900004, 0.02899718, 0.02796984]), 'score_time': array([0.0130012 , 0.01300025, 0.01099992, 0.01097035, 0.01099944,\n",
      "       0.01199913, 0.01097417, 0.00999856, 0.01000166, 0.01100063]), 'test_f1': array([0.54545455, 0.54545455, 0.5       , 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556]), 'test_precision': array([0.54545455, 0.54545455, 0.5       , 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556]), 'test_recall': array([0.54545455, 0.54545455, 0.5       , 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556])}\n"
     ]
    }
   ],
   "source": [
    "for clf in ClassifierFactory.get_text_classifiers(df_txt_train, df_targets_train):\n",
    "    print(clf.cv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def majorityVoting(resMat):\n",
    "    resMat=resMat.astype(int)\n",
    "    res=[]\n",
    "    for x in range(0,len(resMat)):\n",
    "        res.append(np.bincount(resMat[x]).argmax())\n",
    "        \n",
    "    return res\n",
    "    \n",
    "def labelStacking(resMat):\n",
    "    resMat=resMat.astype(int)\n",
    "    res=[]\n",
    "    for x in range(0,len(resMat)):\n",
    "        res.append(np.bincount(resMat[x]).argmax())\n",
    "        \n",
    "    return res\n",
    "    \n",
    "    \n",
    "d = np.zeros((3,4))    \n",
    "d[0,0]=1\n",
    "d[0,1]=1\n",
    "d[0,2]=1\n",
    "d[0,3]=0\n",
    "d[2,2]=1\n",
    "\n",
    "print(majorityVoting(d))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
